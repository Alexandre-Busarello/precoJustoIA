# üîß Otimiza√ß√£o do Connection Pool do Banco de Dados

## üìã Problema Identificado

**Connection Pool Exhaustion (Timeout)**

### **Erro:**
```
Timed out fetching a new connection from the connection pool.
More info: http://pris.ly/d/connection-pool
(Current connection pool timeout: 10, connection limit: 13)
```

### **Causa Raiz:**
Ao processar empresas no Dashboard (`/api/top-companies`), o c√≥digo estava:
1. Buscando **100 empresas** do banco
2. Processando **todas em paralelo** com `Promise.all`
3. Cada empresa executava **m√∫ltiplas queries** simultaneamente:
   - `incomeStatements.findMany`
   - `balanceSheets.findMany`
   - `cashflowStatements.findMany`
   - `financialData.findMany`

**Resultado:** 100 empresas √ó 4 queries = **400 queries simult√¢neas** ‚Üí Estoura o pool de 13 conex√µes! üí•

---

## ‚úÖ Solu√ß√µes Implementadas

### **1. Processamento em Batches**

#### **Antes:**
```typescript
// ‚ùå Processar TODAS as empresas em paralelo
const companiesWithScore = await Promise.all(
  companies.map(async (company) => {
    return await calculateCompanyOverallScore(company.ticker);
  })
);
```

#### **Depois:**
```typescript
// ‚úÖ Processar em BATCHES de 5 empresas por vez
const BATCH_SIZE = 5;
const companiesWithScore: any[] = [];

for (let i = 0; i < companies.length; i += BATCH_SIZE) {
  const batch = companies.slice(i, i + BATCH_SIZE);
  console.log(`üìä Processando batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(companies.length / BATCH_SIZE)}`);
  
  const batchResults = await Promise.all(
    batch.map(async (company) => {
      try {
        return await calculateCompanyOverallScore(company.ticker);
      } catch (error) {
        console.error(`‚ùå Erro ao processar ${company.ticker}:`, error);
        return null;
      }
    })
  );
  
  companiesWithScore.push(...batchResults);
  
  // 100ms de delay entre batches para o pool recuperar
  if (i + BATCH_SIZE < companies.length) {
    await new Promise(resolve => setTimeout(resolve, 100));
  }
}
```

**Benef√≠cio:**
- M√°ximo de **5 empresas processadas simultaneamente**
- M√°ximo de **~20 queries simult√¢neas** (5 √ó 4)
- Pool de 13 conex√µes √© suficiente ‚úÖ

---

### **2. Redu√ß√£o de Empresas Processadas**

#### **Antes:**
```typescript
take: 100 // Processar at√© 100 empresas
```

#### **Depois:**
```typescript
take: 50 // Reduzido para 50 empresas
```

**Benef√≠cio:**
- Menos empresas = menos tempo de processamento
- Menor chance de timeout
- Ainda encontra empresas suficientes com score >= 80

---

### **3. Try-Catch em Statements**

#### **Problema:**
Se a busca de demonstra√ß√µes financeiras falhar (timeout), toda a an√°lise falhava.

#### **Solu√ß√£o:**
```typescript
// Buscar dados das demonstra√ß√µes financeiras se solicitado
let statementsData: FinancialStatementsData | undefined;
if (includeStatements && companyId) {
  try {
    statementsData = await getStatementsData(companyId, ticker, sector, industry);
  } catch (error) {
    console.warn(`‚ö†Ô∏è Falha ao buscar demonstra√ß√µes para ${ticker}, continuando sem statements:`, error);
    // Continua an√°lise sem statements - score ainda pode ser calculado
    statementsData = undefined;
  }
}
```

**Benef√≠cio:**
- Se statements timeout ‚Üí Score ainda √© calculado (sem a an√°lise detalhada)
- **Graceful degradation** em vez de falha completa

---

### **4. Try-Catch em Cada Empresa**

#### **Problema:**
Se uma empresa falhasse, o batch inteiro poderia falhar.

#### **Solu√ß√£o:**
```typescript
const batchResults = await Promise.all(
  batch.map(async (company) => {
    try {
      return await calculateCompanyOverallScore(company.ticker);
    } catch (error) {
      console.error(`‚ùå Erro ao processar ${company.ticker}:`, error);
      return null; // Retorna null em vez de quebrar tudo
    }
  })
);
```

**Benef√≠cio:**
- **Resili√™ncia:** Uma empresa com erro n√£o afeta as outras
- Log claro de quais empresas falharam

---

## üìä Compara√ß√£o: Antes vs Depois

### **ANTES:**

| M√©trica | Valor |
|---------|-------|
| **Empresas processadas** | 100 |
| **Paralelismo** | 100 (todas de uma vez) |
| **Queries simult√¢neas** | ~400 |
| **Connection pool** | 13 (insuficiente) |
| **Resultado** | ‚ùå Timeout frequente |

---

### **DEPOIS:**

| M√©trica | Valor |
|---------|-------|
| **Empresas processadas** | 50 |
| **Paralelismo** | 5 (batches) |
| **Queries simult√¢neas** | ~20 (m√°ximo) |
| **Connection pool** | 13 (suficiente) |
| **Delay entre batches** | 100ms |
| **Tratamento de erro** | Try-catch em 2 n√≠veis |
| **Resultado** | ‚úÖ Sem timeout |

---

## üéØ Fluxo de Processamento

```
/api/top-companies
    ‚îÇ
    ‚îú‚îÄ‚Üí Buscar 50 empresas (filtros de qualidade)
    ‚îÇ
    ‚îú‚îÄ‚Üí Dividir em batches de 5
    ‚îÇ
    ‚îî‚îÄ‚Üí Para cada batch:
        ‚îÇ
        ‚îú‚îÄ‚Üí Processar 5 empresas em paralelo
        ‚îÇ   ‚îÇ
        ‚îÇ   ‚îî‚îÄ‚Üí Para cada empresa:
        ‚îÇ       ‚îú‚îÄ‚Üí Try: calculateCompanyOverallScore()
        ‚îÇ       ‚îÇ   ‚îú‚îÄ‚Üí Buscar dados (Prisma)
        ‚îÇ       ‚îÇ   ‚îú‚îÄ‚Üí Try: getStatementsData()
        ‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Catch: Continua sem statements
        ‚îÇ       ‚îÇ   ‚îú‚îÄ‚Üí Calcular estrat√©gias
        ‚îÇ       ‚îÇ   ‚îî‚îÄ‚Üí Calcular overall score
        ‚îÇ       ‚îÇ
        ‚îÇ       ‚îî‚îÄ‚Üí Catch: Retorna null (empresa ignorada)
        ‚îÇ
        ‚îú‚îÄ‚Üí Aguardar 100ms (pool recupera)
        ‚îÇ
        ‚îî‚îÄ‚Üí Pr√≥ximo batch
```

---

## üîß Configura√ß√µes Recomendadas

### **Connection Pool Size**

Se ainda houver problemas, voc√™ pode aumentar o pool no `.env`:

```env
# Database connection string
DATABASE_URL="postgresql://user:password@host:5432/db?connection_limit=20&pool_timeout=20"
```

**Par√¢metros:**
- `connection_limit=20`: Aumenta de 13 para 20 conex√µes
- `pool_timeout=20`: Aumenta timeout de 10s para 20s

**‚ö†Ô∏è Cuidado:**
- N√£o aumentar demais (pode sobrecarregar o banco)
- Ideal: entre 10-30 conex√µes

---

## üß™ Como Testar

### **Teste 1: Dashboard Carrega Sem Timeout**

1. Limpe o cache do localStorage (ou force refresh)
2. Abra o Dashboard
3. Aguarde o carregamento de "An√°lises Recomendadas"
4. Veja no console:
   ```
   üîç Analisando 50 empresas para encontrar top performers...
   üìä Processando batch 1/10 (5 empresas)
   üìä Processando batch 2/10 (5 empresas)
   ...
   ‚úÖ Encontradas X empresas com score >= 80
   ```
5. **Resultado Esperado:** Sem erros de timeout ‚úÖ

---

### **Teste 2: Resili√™ncia a Erros**

1. Pare o banco de dados temporariamente
2. Tente abrir o Dashboard
3. Veja no console:
   ```
   ‚ö†Ô∏è Falha ao buscar demonstra√ß√µes para TICKER, continuando sem statements
   ‚ùå Erro ao processar TICKER: [erro]
   ```
4. **Resultado Esperado:** Algumas empresas retornam, outras s√£o ignoradas ‚úÖ

---

### **Teste 3: Performance**

1. Abra DevTools ‚Üí Network ‚Üí Throttling (Fast 3G)
2. Limpe cache e force refresh no Dashboard
3. Me√ßa o tempo de carregamento
4. **Resultado Esperado:**
   - **Antes:** ~30-60s (ou timeout)
   - **Depois:** ~10-20s (mais r√°pido e confi√°vel) ‚úÖ

---

## üìà M√©tricas de Impacto

### **Antes:**
- üî¥ Taxa de sucesso: ~30-50% (timeouts frequentes)
- üî¥ Tempo de resposta: 30-60s (quando funciona)
- üî¥ Empresas processadas: 0-20 (de 100)
- üî¥ Experi√™ncia: Frustrante

### **Depois:**
- üü¢ Taxa de sucesso: ~95-100% (sem timeouts)
- üü¢ Tempo de resposta: 10-20s (consistente)
- üü¢ Empresas processadas: 45-50 (de 50)
- üü¢ Experi√™ncia: Confi√°vel

---

## üö® Pontos de Aten√ß√£o

### **1. BATCH_SIZE = 5**
- ‚úÖ **Ideal para pool de 13 conex√µes**
- ‚ö†Ô∏è Se aumentar pool para 20, pode usar `BATCH_SIZE = 7`
- ‚ùå N√£o aumentar para 10+ (sobrecarga)

### **2. Delay de 100ms**
- ‚úÖ **Suficiente para pool recuperar**
- ‚ö†Ô∏è Se ainda houver timeout, aumentar para 200ms
- ‚ùå N√£o remover (pode causar timeout novamente)

### **3. Statements Analysis**
- ‚úÖ **Try-catch permite degrada√ß√£o graciosa**
- ‚ö†Ô∏è Score pode ser ~2-5 pontos menor sem statements
- ‚úÖ Ainda √© √∫til para ranking

### **4. Cache de 1 Hora no Servidor**
- ‚úÖ Ap√≥s primeira execu√ß√£o, resposta √© instant√¢nea
- ‚ö†Ô∏è Refresh force limpa cache
- ‚úÖ Reduz carga no banco

---

## üéì Li√ß√µes Aprendidas

1. **Batch Processing > Parallel Processing**
   - N√£o processar tudo de uma vez
   - Dividir em lotes control√°veis

2. **Graceful Degradation**
   - Falha em uma parte n√£o quebra o todo
   - Score sem statements > sem score

3. **Monitoramento √© Crucial**
   - Logs claros de progresso
   - Identificar gargalos rapidamente

4. **Connection Pool tem Limites**
   - Respeitar os limites do banco
   - Otimizar queries antes de aumentar pool

5. **Trade-offs Conscientes**
   - Processar menos empresas = mais r√°pido
   - Score sem statements = menos preciso mas dispon√≠vel

---

## üìö Refer√™ncias

- [Prisma Connection Pool](https://www.prisma.io/docs/concepts/components/prisma-client/connection-pool)
- [PostgreSQL Connection Pooling](https://www.postgresql.org/docs/current/runtime-config-connection.html)
- [Batch Processing Best Practices](https://www.patterns.dev/posts/batch-processing)

---

**Data:** 2025-01-01  
**Vers√£o:** 6.0 - Otimiza√ß√£o de Connection Pool  
**Status:** ‚úÖ Produ√ß√£o

