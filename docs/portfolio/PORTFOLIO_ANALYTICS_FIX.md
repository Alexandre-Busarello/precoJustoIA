# Corre√ß√£o: Connection Pool Exhaustion no Analytics

## Problema Identificado

Ao acessar a aba "An√°lises" da carteira, ocorria um **connection pool exhaustion** causado por:

1. **M√∫ltiplos upserts simult√¢neos**: `saveHistoricalData` executava centenas de `safeWrite` em paralelo via `Promise.all`
2. **Busca excessiva de dados**: `fetchMaximumHistoricalData` tentava buscar 20 anos de dados para todos os ativos simultaneamente
3. **Processamento paralelo de tickers**: Todos os tickers eram processados ao mesmo tempo

### Erro Original
```
Timed out fetching a new connection from the connection pool. 
More info: http://pris.ly/d/connection-pool 
(Current connection pool timeout: 10, connection limit: 13)
```

## Corre√ß√µes Aplicadas

### 1. Batch Processing em `saveHistoricalData`

**Arquivo**: `src/lib/historical-data-service.ts`

**Antes**:
```typescript
// Executava todos os upserts em paralelo
await Promise.all(
  data.map(point => safeWrite('upsert-historical_prices', ...))
);
```

**Depois**:
```typescript
// Processa em lotes de 50
const BATCH_SIZE = 50;
for (let i = 0; i < data.length; i += BATCH_SIZE) {
  const batch = data.slice(i, i + BATCH_SIZE);
  await Promise.all(
    batch.map(point => prisma.historicalPrice.upsert(...))
  );
}
```

**Benef√≠cios**:
- ‚úÖ Limita conex√µes simult√¢neas a 50 (bem abaixo do limite de 13)
- ‚úÖ Remove overhead de `safeWrite` para opera√ß√µes em massa
- ‚úÖ Adiciona logs de progresso para lotes grandes

### 2. Processamento Sequencial de Tickers

**Arquivo**: `src/lib/portfolio-analytics-service.ts`

**Antes**:
```typescript
// Processava todos os tickers em paralelo
await Promise.all(
  tickers.map(ticker =>
    HistoricalDataService.fetchMaximumHistoricalData(ticker, '1mo')
  )
);
```

**Depois**:
```typescript
// Processa um ticker por vez
for (const ticker of tickers) {
  try {
    await HistoricalDataService.ensureHistoricalData(
      ticker,
      startDate, // Apenas o per√≠odo necess√°rio
      endDate,
      '1mo',
      false // N√£o buscar m√°ximo (20 anos)
    );
  } catch (error) {
    console.error(`‚ö†Ô∏è Erro ao buscar dados de ${ticker}:`, error);
    // Continua com pr√≥ximo ticker
  }
}
```

**Benef√≠cios**:
- ‚úÖ Evita esgotamento do pool processando sequencialmente
- ‚úÖ Busca apenas o per√≠odo necess√°rio (n√£o 20 anos)
- ‚úÖ Tratamento de erro por ticker (n√£o falha tudo se um ticker der erro)
- ‚úÖ Continua com outros tickers mesmo se um falhar

## Impacto

### Performance
- **Antes**: Timeout ap√≥s 25+ segundos, falha completa
- **Depois**: Processamento mais lento mas confi√°vel (3-10s por ticker)

### Estabilidade
- ‚úÖ N√£o esgota mais o connection pool
- ‚úÖ Tratamento robusto de erros
- ‚úÖ Logs informativos de progresso

### Dados
- ‚úÖ Busca apenas o per√≠odo necess√°rio para analytics
- ‚úÖ Evita buscar 20 anos de dados desnecessariamente

## Otimiza√ß√µes Adicionais (Implementadas em 20/10/2025)

### 1. ‚úÖ Verifica√ß√£o Otimizada de Dados Existentes

**Problema**: Cada ticker era verificado individualmente, causando lentid√£o.

**Solu√ß√£o**: Criado m√©todo `getTickersNeedingHistoricalData()` que:
- Faz uma **√∫nica consulta** ao banco usando `groupBy` para todos os tickers
- Verifica cobertura de dados (80% threshold)
- Retorna apenas tickers que realmente precisam de dados

```typescript
// Batch check para todos os tickers de uma vez
const tickersNeedingData = await this.getTickersNeedingHistoricalData(
  tickers,
  startDate,
  endDate,
  '1mo'
);

// Busca dados apenas para os que precisam
for (const ticker of tickersNeedingData) {
  await HistoricalDataService.ensureHistoricalData(...);
}
```

**Benef√≠cios**:
- ‚úÖ Reduz queries ao banco de N para 2 (groupBy + findMany)
- ‚úÖ Pula tickers que j√° t√™m dados suficientes
- ‚úÖ Melhora significativa de performance para carteiras com muitos ativos

### 2. ‚úÖ Corre√ß√£o da L√≥gica de Evolu√ß√£o

**Problema**: Loop aplicava **todas** as transa√ß√µes para cada data mensal, causando:
- Retornos absurdos (ex: 95.80% em um √∫nico m√™s)
- Duplica√ß√£o de transa√ß√µes
- C√°lculos completamente incorretos

**Solu√ß√£o**: Rastreamento de transa√ß√µes processadas:

```typescript
let lastProcessedTxIndex = 0;

for (const date of monthlyDates) {
  // Processa apenas transa√ß√µes NOVAS at√© esta data
  while (lastProcessedTxIndex < transactions.length) {
    const tx = transactions[lastProcessedTxIndex];
    if (tx.date > date) break;
    
    // Aplica transa√ß√£o UMA vez
    // ...
    lastProcessedTxIndex++;
  }
  // Calcula valor da carteira nesta data
}
```

**Benef√≠cios**:
- ‚úÖ Cada transa√ß√£o aplicada exatamente uma vez
- ‚úÖ Retornos mensais corretos
- ‚úÖ Evolu√ß√£o da carteira precisa

### 3. ‚úÖ Dividendos Inclu√≠dos no Retorno

**Problema**: Dividendos n√£o eram contabilizados corretamente no c√°lculo de retorno.

**Solu√ß√£o**: L√≥gica correta para dividendos:
- Dividendos aumentam `cashBalance` mas **n√£o** `totalInvested`
- Se ficam em caixa ‚Üí j√° inclu√≠dos no `totalValue`
- Se s√£o sacados ‚Üí adicionados via `totalWithdrawals`

```typescript
// Dividendos aumentam caixa, n√£o investimento
if (tx.type === 'DIVIDEND') {
  cashBalance += Number(tx.amount);
  // N√£o adiciona ao totalInvested
}

// Retorno considera saques (incluindo dividendos sacados)
const returnAmount = totalValue + totalWithdrawals - totalInvested;
```

**Benef√≠cios**:
- ‚úÖ Dividendos contabilizados como retorno
- ‚úÖ Funciona corretamente se mantidos em caixa ou sacados
- ‚úÖ Funciona corretamente se reinvestidos

## Pr√≥ximas Otimiza√ß√µes Sugeridas

### 1. Cache de Analytics
Cachear o resultado do c√°lculo de analytics por algumas horas:

```typescript
const cacheKey = `analytics:${portfolioId}:${lastTransactionDate}`;
const cached = await cache.get(cacheKey);
if (cached) return cached;
// ... calcular ...
await cache.set(cacheKey, result, 3600); // 1 hora
```

### 2. Background Job para Dados Hist√≥ricos
Processar dados hist√≥ricos em background quando um ativo √© adicionado √† carteira, n√£o sob demanda.

## Como Testar

1. **Reiniciar servidor** para aplicar as mudan√ßas
2. **Acessar aba An√°lises** de uma carteira
3. **Verificar logs**:
   - `üìä [ANALYTICS] Garantindo dados hist√≥ricos para X ativos...`
   - `üìä [DB] Processados X/Y pontos hist√≥ricos` (para lotes grandes)
   - `‚úÖ [ANALYTICS] Dados hist√≥ricos garantidos para todos os ativos`
4. **Confirmar sucesso**: Gr√°ficos de evolu√ß√£o s√£o exibidos
5. **Verificar tempo**: Deve completar em ~1-2 minutos para carteira com 5-10 ativos

## Monitoramento

Observar nos logs:
- ‚ùå **Erros de timeout**: N√£o devem mais ocorrer
- ‚úÖ **Logs de progresso**: Indicam processamento saud√°vel
- ‚ö†Ô∏è **Avisos de erro por ticker**: Alguns tickers podem falhar (esperado)

---

**Data**: 20 de Outubro de 2025  
**Status**: ‚úÖ Corrigido

